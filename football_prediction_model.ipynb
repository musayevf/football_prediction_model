{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading datasets forming a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 8214\n",
      "Number of columns: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>B365H</th>\n",
       "      <th>B365D</th>\n",
       "      <th>B365A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17/08/2002</td>\n",
       "      <td>Blackburn</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>D</td>\n",
       "      <td>1.727</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17/08/2002</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>A</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17/08/2002</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>D</td>\n",
       "      <td>2.250</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17/08/2002</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>Bolton</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.727</td>\n",
       "      <td>3.25</td>\n",
       "      <td>4.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17/08/2002</td>\n",
       "      <td>Leeds</td>\n",
       "      <td>Man City</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>H</td>\n",
       "      <td>1.667</td>\n",
       "      <td>3.40</td>\n",
       "      <td>4.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date   HomeTeam    AwayTeam  FTHG  FTAG FTR  B365H  B365D  B365A\n",
       "0  17/08/2002  Blackburn  Sunderland   0.0   0.0   D  1.727   3.25  4.333\n",
       "1  17/08/2002   Charlton     Chelsea   2.0   3.0   A  2.800   3.25  2.200\n",
       "2  17/08/2002    Everton   Tottenham   2.0   2.0   D  2.250   3.25  2.750\n",
       "3  17/08/2002     Fulham      Bolton   4.0   1.0   H  1.727   3.25  4.333\n",
       "4  17/08/2002      Leeds    Man City   3.0   0.0   H  1.667   3.40  4.500"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from scipy.stats import poisson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "directory = 'C:/Users/99451/Desktop/MODEL/eng_prem'\n",
    "\n",
    "dfs = []\n",
    "\n",
    "# Define the columns you want to extract from each CSV file\n",
    "columns_to_keep = ['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'B365H', 'B365D', 'B365A']\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        df = pd.read_csv(os.path.join(directory, filename), on_bad_lines = 'skip', encoding='latin-1')\n",
    "        df = df[columns_to_keep]\n",
    "        dfs.append(df)\n",
    "\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Number of rows:\", df.shape[0])\n",
    "print(\"Number of columns:\", df.shape[1])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Moving Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HPPG</th>\n",
       "      <th>APPG</th>\n",
       "      <th>FTH</th>\n",
       "      <th>FTDA</th>\n",
       "      <th>home_poisson</th>\n",
       "      <th>away_poisson</th>\n",
       "      <th>poisson_df</th>\n",
       "      <th>FTRT</th>\n",
       "      <th>form_dif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>D</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536974</td>\n",
       "      <td>0.463026</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>H</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.389014</td>\n",
       "      <td>0.610986</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Fulham</td>\n",
       "      <td>H</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.398329</td>\n",
       "      <td>0.601671</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Arsenal</td>\n",
       "      <td>H</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.162360</td>\n",
       "      <td>0.837640</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Charlton</td>\n",
       "      <td>H</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.537421</td>\n",
       "      <td>0.462579</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Everton</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>H</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.622124</td>\n",
       "      <td>0.377876</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Everton</td>\n",
       "      <td>Chelsea</td>\n",
       "      <td>A</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.359551</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    HomeTeam       AwayTeam FTR      HPPG      APPG       FTH      FTDA  \\\n",
       "4    Everton     Birmingham   D  1.000000  0.000000  0.536974  0.463026   \n",
       "31   Everton  Middlesbrough   H  1.000000  0.500000  0.389014  0.610986   \n",
       "52   Everton         Fulham   H  1.666667  1.333333  0.398329  0.601671   \n",
       "69   Everton        Arsenal   H  2.000000  2.000000  0.162360  0.837640   \n",
       "103  Everton       Charlton   H  2.200000  0.800000  0.537421  0.462579   \n",
       "121  Everton      West Brom   H  2.600000  0.800000  0.622124  0.377876   \n",
       "142  Everton        Chelsea   A  3.000000  1.200000  0.359551  0.640449   \n",
       "\n",
       "     home_poisson  away_poisson  poisson_df  FTRT  form_dif  \n",
       "4               2             0           2     0  1.000000  \n",
       "31              0             0           0     1  0.500000  \n",
       "52              1             2          -1     1  0.333333  \n",
       "69              1             2          -1     1  0.000000  \n",
       "103             1             0           1     1  1.400000  \n",
       "121             1             0           1     1  1.800000  \n",
       "142             0             0           0     0  1.800000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Calculating Points Per Game for Home and Away Teams\n",
    "df['HPTS'] = np.select([df['FTR'] == 'H', df['FTR'] == 'D', df['FTR'] == 'A'], [3, 1, 0], default=0)\n",
    "df['APTS'] = np.select([df['FTR'] == 'H', df['FTR'] == 'D', df['FTR'] == 'A'], [0, 1, 3], default=0)\n",
    "\n",
    "df['HPPG'] = df.groupby('HomeTeam')['HPTS'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "df['APPG'] = df.groupby('AwayTeam')['APTS'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "\n",
    "#Calculating scored and conceded goals\n",
    "df['FTHGS'] = df.groupby('HomeTeam')['FTHG'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "df['FTHGC'] = df.groupby('HomeTeam')['FTAG'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "\n",
    "df['FTAGS'] = df.groupby('AwayTeam')['FTAG'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "df['FTAGC'] = df.groupby('AwayTeam')['FTHG'].transform(lambda x: x.rolling(5, min_periods=1).mean().shift(1))\n",
    "\n",
    "#Calculating odds probabilities\n",
    "total = 1 / df['B365H'] + 1 / df['B365D'] + 1 / df['B365A']\n",
    "\n",
    "df['FTH'] = (1 / df['B365H']) / total\n",
    "df['FTD'] = (1 / df['B365D']) / total\n",
    "df['FTA'] = (1 / df['B365A']) / total\n",
    "df['FTDA'] = df['FTD'] + df['FTA']\n",
    "\n",
    "# Calculate the league-wide moving average for home_goals and away_goals\n",
    "df['league_home_goals'] = df['FTHG'].rolling(50, min_periods=1).mean().shift(1)\n",
    "df['league_away_goals'] = df['FTAG'].rolling(50, min_periods=1).mean().shift(1)\n",
    "\n",
    "#Calculating Poisson Statistics\n",
    "df['home_attack'] = df['FTHGS'] / df['league_home_goals']\n",
    "df['home_defence'] = df['FTHGC'] / df['league_away_goals']\n",
    "df['away_attack'] = df['FTAGS'] / df['league_away_goals']\n",
    "df['away_defence'] = df['FTAGC'] / df['league_home_goals']\n",
    "\n",
    "df['home_xg'] = df['home_attack'] * df['away_defence'] * df['league_home_goals']\n",
    "df['away_xg'] = df['away_attack'] * df['home_defence'] * df['league_away_goals']\n",
    "df['xg_dif'] = df['home_xg'] - df['away_xg']\n",
    "\n",
    "df.dropna(inplace = True)\n",
    "df = df.reset_index(drop = True)\n",
    "\n",
    "df['home_poisson'] = df['home_xg'].apply(lambda lmbda: np.nanargmax(\n",
    "    [poisson.pmf(k, lmbda) for k in range(int(lmbda * 2))]) \n",
    "    if not pd.isnull(lmbda) and any([poisson.pmf(k, lmbda) for k in range(int(lmbda * 2))]) else 0)\n",
    "\n",
    "df['away_poisson'] = df['away_xg'].apply(lambda lmbda: np.nanargmax(\n",
    "    [poisson.pmf(k, lmbda) for k in range(int(lmbda * 2))]) \n",
    "    if not pd.isnull(lmbda) and any([poisson.pmf(k, lmbda) for k in range(int(lmbda * 2))]) else 0)\n",
    "\n",
    "df['poisson_df'] = df['home_poisson'] - df['away_poisson']\n",
    "df['FTRT'] = [1 if x == 'H' else 0 for x in df['FTR']]\n",
    "df['form_dif'] = df['HPPG'] - df['APPG']\n",
    "\n",
    "#Removing unnessary columns\n",
    "df.drop(['Date', 'FTHG', 'FTAG', 'B365H', 'B365D', 'B365A', 'HPTS', 'APTS', 'FTHGS', 'FTHGC', 'FTAGS', 'FTAGC',\n",
    "            'FTD', 'FTA', 'league_home_goals', 'league_away_goals', 'home_attack', 'home_defence',\n",
    "            'away_attack', 'away_defence', 'home_xg', 'away_xg', 'xg_dif'], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "df[df['HomeTeam'] == 'Everton'].head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Points Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Teams</th>\n",
       "      <th>Points</th>\n",
       "      <th>Games</th>\n",
       "      <th>PPG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Man United</td>\n",
       "      <td>1640</td>\n",
       "      <td>817</td>\n",
       "      <td>2.007344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chelsea</td>\n",
       "      <td>1600</td>\n",
       "      <td>815</td>\n",
       "      <td>1.963190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arsenal</td>\n",
       "      <td>1572</td>\n",
       "      <td>817</td>\n",
       "      <td>1.924113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Liverpool</td>\n",
       "      <td>1561</td>\n",
       "      <td>817</td>\n",
       "      <td>1.910649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Man City</td>\n",
       "      <td>1541</td>\n",
       "      <td>814</td>\n",
       "      <td>1.893120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1376</td>\n",
       "      <td>818</td>\n",
       "      <td>1.682152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Everton</td>\n",
       "      <td>1158</td>\n",
       "      <td>816</td>\n",
       "      <td>1.419118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Leicester</td>\n",
       "      <td>508</td>\n",
       "      <td>372</td>\n",
       "      <td>1.365591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Newcastle</td>\n",
       "      <td>956</td>\n",
       "      <td>740</td>\n",
       "      <td>1.291892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Blackburn</td>\n",
       "      <td>466</td>\n",
       "      <td>366</td>\n",
       "      <td>1.273224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Aston Villa</td>\n",
       "      <td>893</td>\n",
       "      <td>703</td>\n",
       "      <td>1.270270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Brentford</td>\n",
       "      <td>133</td>\n",
       "      <td>107</td>\n",
       "      <td>1.242991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>West Ham</td>\n",
       "      <td>880</td>\n",
       "      <td>711</td>\n",
       "      <td>1.237693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bolton</td>\n",
       "      <td>448</td>\n",
       "      <td>368</td>\n",
       "      <td>1.217391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Brighton</td>\n",
       "      <td>312</td>\n",
       "      <td>257</td>\n",
       "      <td>1.214008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Stoke</td>\n",
       "      <td>451</td>\n",
       "      <td>377</td>\n",
       "      <td>1.196286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Southampton</td>\n",
       "      <td>619</td>\n",
       "      <td>520</td>\n",
       "      <td>1.190385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Charlton</td>\n",
       "      <td>211</td>\n",
       "      <td>178</td>\n",
       "      <td>1.185393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Swansea</td>\n",
       "      <td>311</td>\n",
       "      <td>264</td>\n",
       "      <td>1.178030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wolves</td>\n",
       "      <td>430</td>\n",
       "      <td>367</td>\n",
       "      <td>1.171662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>507</td>\n",
       "      <td>442</td>\n",
       "      <td>1.147059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Birmingham</td>\n",
       "      <td>292</td>\n",
       "      <td>256</td>\n",
       "      <td>1.140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Fulham</td>\n",
       "      <td>669</td>\n",
       "      <td>589</td>\n",
       "      <td>1.135823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bournemouth</td>\n",
       "      <td>292</td>\n",
       "      <td>258</td>\n",
       "      <td>1.131783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Middlesbrough</td>\n",
       "      <td>330</td>\n",
       "      <td>293</td>\n",
       "      <td>1.126280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Portsmouth</td>\n",
       "      <td>283</td>\n",
       "      <td>255</td>\n",
       "      <td>1.109804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wigan</td>\n",
       "      <td>330</td>\n",
       "      <td>300</td>\n",
       "      <td>1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Leeds</td>\n",
       "      <td>195</td>\n",
       "      <td>183</td>\n",
       "      <td>1.065574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Reading</td>\n",
       "      <td>116</td>\n",
       "      <td>112</td>\n",
       "      <td>1.035714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Burnley</td>\n",
       "      <td>342</td>\n",
       "      <td>335</td>\n",
       "      <td>1.020896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>West Brom</td>\n",
       "      <td>485</td>\n",
       "      <td>487</td>\n",
       "      <td>0.995893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Watford</td>\n",
       "      <td>260</td>\n",
       "      <td>264</td>\n",
       "      <td>0.984848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Blackpool</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Nott'm Forest</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>0.942029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Sunderland</td>\n",
       "      <td>422</td>\n",
       "      <td>454</td>\n",
       "      <td>0.929515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Sheffield United</td>\n",
       "      <td>130</td>\n",
       "      <td>144</td>\n",
       "      <td>0.902778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Hull</td>\n",
       "      <td>167</td>\n",
       "      <td>188</td>\n",
       "      <td>0.888298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Norwich</td>\n",
       "      <td>227</td>\n",
       "      <td>260</td>\n",
       "      <td>0.873077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Cardiff</td>\n",
       "      <td>61</td>\n",
       "      <td>74</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Luton</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>QPR</td>\n",
       "      <td>89</td>\n",
       "      <td>112</td>\n",
       "      <td>0.794643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>47</td>\n",
       "      <td>74</td>\n",
       "      <td>0.635135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Derby</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Teams  Points  Games       PPG\n",
       "0         Man United    1640    817  2.007344\n",
       "1            Chelsea    1600    815  1.963190\n",
       "2            Arsenal    1572    817  1.924113\n",
       "3          Liverpool    1561    817  1.910649\n",
       "4           Man City    1541    814  1.893120\n",
       "5          Tottenham    1376    818  1.682152\n",
       "6            Everton    1158    816  1.419118\n",
       "7          Leicester     508    372  1.365591\n",
       "8          Newcastle     956    740  1.291892\n",
       "9          Blackburn     466    366  1.273224\n",
       "10       Aston Villa     893    703  1.270270\n",
       "11         Brentford     133    107  1.242991\n",
       "12          West Ham     880    711  1.237693\n",
       "13            Bolton     448    368  1.217391\n",
       "14          Brighton     312    257  1.214008\n",
       "15             Stoke     451    377  1.196286\n",
       "16       Southampton     619    520  1.190385\n",
       "17          Charlton     211    178  1.185393\n",
       "18           Swansea     311    264  1.178030\n",
       "19            Wolves     430    367  1.171662\n",
       "20    Crystal Palace     507    442  1.147059\n",
       "21        Birmingham     292    256  1.140625\n",
       "22            Fulham     669    589  1.135823\n",
       "23       Bournemouth     292    258  1.131783\n",
       "24     Middlesbrough     330    293  1.126280\n",
       "25        Portsmouth     283    255  1.109804\n",
       "26             Wigan     330    300  1.100000\n",
       "27             Leeds     195    183  1.065574\n",
       "28           Reading     116    112  1.035714\n",
       "29           Burnley     342    335  1.020896\n",
       "30         West Brom     485    487  0.995893\n",
       "31           Watford     260    264  0.984848\n",
       "32         Blackpool      35     36  0.972222\n",
       "33     Nott'm Forest      65     69  0.942029\n",
       "34        Sunderland     422    454  0.929515\n",
       "35  Sheffield United     130    144  0.902778\n",
       "36              Hull     167    188  0.888298\n",
       "37           Norwich     227    260  0.873077\n",
       "38           Cardiff      61     74  0.824324\n",
       "39             Luton      25     31  0.806452\n",
       "40               QPR      89    112  0.794643\n",
       "41      Huddersfield      47     74  0.635135\n",
       "42             Derby      10     36  0.277778"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating Table According to Performance\n",
    "point = 0\n",
    "game = 0\n",
    "teams = np.unique(df['HomeTeam'])\n",
    "\n",
    "points = []\n",
    "games = []\n",
    "team_names = []\n",
    "\n",
    "for team in teams:\n",
    "    for j in range(len(df['HomeTeam'])):\n",
    "        if team == df['HomeTeam'][j]:\n",
    "            game += 1\n",
    "            if df['FTR'][j] == 'H':\n",
    "                point += 3\n",
    "            elif df['FTR'][j] == 'D':\n",
    "                point += 1\n",
    "        elif team == df['AwayTeam'][j]:\n",
    "            game += 1\n",
    "            if df['FTR'][j] == 'A':\n",
    "                point += 3\n",
    "            elif df['FTR'][j] == 'D':\n",
    "                point += 1\n",
    "    points.append(point)\n",
    "    team_names.append(team)\n",
    "    games.append(game)\n",
    "    point = 0\n",
    "    ft_scored = 0\n",
    "    ft_conceded = 0\n",
    "    ht_scored = 0\n",
    "    ht_conceded = 0\n",
    "    game = 0\n",
    "\n",
    "\n",
    "table = pd.DataFrame({\n",
    "    'Teams': team_names,\n",
    "    'Points': points,\n",
    "    'Games': games,\n",
    "})\n",
    "\n",
    "table['PPG'] = table['Points'] / table['Games']\n",
    "table = table.sort_values(by = 'PPG', ascending = False).reset_index(drop = True)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HPPG</th>\n",
       "      <th>APPG</th>\n",
       "      <th>FTH</th>\n",
       "      <th>FTDA</th>\n",
       "      <th>home_poisson</th>\n",
       "      <th>away_poisson</th>\n",
       "      <th>poisson_df</th>\n",
       "      <th>FTRT</th>\n",
       "      <th>form_dif</th>\n",
       "      <th>HomePoints</th>\n",
       "      <th>AwayPoints</th>\n",
       "      <th>Difference</th>\n",
       "      <th>PpgDif</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8138</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>H</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.351011</td>\n",
       "      <td>0.648989</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.291892</td>\n",
       "      <td>1.682152</td>\n",
       "      <td>-3</td>\n",
       "      <td>-0.390260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8139</th>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>H</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.662454</td>\n",
       "      <td>0.337546</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1.242991</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>24</td>\n",
       "      <td>0.340213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>D</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.271493</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.020896</td>\n",
       "      <td>1.214008</td>\n",
       "      <td>-15</td>\n",
       "      <td>-0.193112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8141</th>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>H</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.893120</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>35</td>\n",
       "      <td>1.086669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8142</th>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>D</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.450928</td>\n",
       "      <td>0.549072</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.942029</td>\n",
       "      <td>1.171662</td>\n",
       "      <td>-14</td>\n",
       "      <td>-0.229633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8143</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.393939</td>\n",
       "      <td>0.606061</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.131783</td>\n",
       "      <td>2.007344</td>\n",
       "      <td>-23</td>\n",
       "      <td>-0.875561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8144</th>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>A</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.783728</td>\n",
       "      <td>0.216272</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.910649</td>\n",
       "      <td>1.147059</td>\n",
       "      <td>17</td>\n",
       "      <td>0.763590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8145</th>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "      <td>A</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.398230</td>\n",
       "      <td>0.601770</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.237693</td>\n",
       "      <td>1.135823</td>\n",
       "      <td>10</td>\n",
       "      <td>0.101870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8146</th>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>A</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.738908</td>\n",
       "      <td>0.261092</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.924113</td>\n",
       "      <td>1.270270</td>\n",
       "      <td>8</td>\n",
       "      <td>0.653842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8147</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>H</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.560997</td>\n",
       "      <td>0.439003</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.963190</td>\n",
       "      <td>1.419118</td>\n",
       "      <td>5</td>\n",
       "      <td>0.544073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      HomeTeam  AwayTeam FTR  HPPG  APPG       FTH      FTDA  home_poisson  \\\n",
       "8138         9         6   H   1.8   1.2  0.351011  0.648989             2   \n",
       "8139        12        36   H   0.6   0.8  0.662454  0.337546             1   \n",
       "8140        30        15   D   1.0   0.8  0.271493  0.728507             0   \n",
       "8141         5        40   H   2.2   0.2  0.863636  0.136364             2   \n",
       "8142        34        20   D   1.4   1.4  0.450928  0.549072             1   \n",
       "8143        24         1   D   2.0   1.4  0.393939  0.606061             1   \n",
       "8144         4        21   A   2.6   0.4  0.783728  0.216272             2   \n",
       "8145        13        23   A   1.2   1.0  0.398230  0.601770             1   \n",
       "8146         3        11   A   3.0   2.0  0.738908  0.261092             2   \n",
       "8147         2         7   H   2.0   0.4  0.560997  0.439003             2   \n",
       "\n",
       "      away_poisson  poisson_df  FTRT  form_dif  HomePoints  AwayPoints  \\\n",
       "8138             2           0     1       0.6    1.291892    1.682152   \n",
       "8139             2          -1     1      -0.2    1.242991    0.902778   \n",
       "8140             2          -2     0       0.2    1.020896    1.214008   \n",
       "8141             0           2     1       2.0    1.893120    0.806452   \n",
       "8142             1           0     0       0.0    0.942029    1.171662   \n",
       "8143             1           0     0       0.6    1.131783    2.007344   \n",
       "8144             0           2     0       2.2    1.910649    1.147059   \n",
       "8145             3          -2     0       0.2    1.237693    1.135823   \n",
       "8146             1           1     0       1.0    1.924113    1.270270   \n",
       "8147             0           2     1       1.6    1.963190    1.419118   \n",
       "\n",
       "      Difference    PpgDif  \n",
       "8138          -3 -0.390260  \n",
       "8139          24  0.340213  \n",
       "8140         -15 -0.193112  \n",
       "8141          35  1.086669  \n",
       "8142         -14 -0.229633  \n",
       "8143         -23 -0.875561  \n",
       "8144          17  0.763590  \n",
       "8145          10  0.101870  \n",
       "8146           8  0.653842  \n",
       "8147           5  0.544073  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary mapping team names to their indices\n",
    "team_indices = {team: index + 1 for index, team in enumerate(table['Teams'])}\n",
    "\n",
    "# Create a dictionary mapping team names to points\n",
    "team_points_dict = table.set_index('Teams')['PPG'].to_dict()\n",
    "\n",
    "# Map points to home team in df_matches\n",
    "df['HomePoints'] = df['HomeTeam'].map(team_points_dict)\n",
    "df['AwayPoints'] = df['AwayTeam'].map(team_points_dict)\n",
    "\n",
    "# Replace 'home' and 'away' team names with their indices from df2\n",
    "df['HomeTeam'] = df['HomeTeam'].map(team_indices)\n",
    "df['AwayTeam'] = df['AwayTeam'].map(team_indices)\n",
    "\n",
    "df['Difference'] = df['AwayTeam'] - df['HomeTeam']\n",
    "df['PpgDif'] = df['HomePoints'] - df['AwayPoints']\n",
    "\n",
    "df.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying with Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:577: FutureWarning: The default of `sampling_strategy` will change from `'auto'` to `'all'` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `'all'` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:589: FutureWarning: The default of `replacement` will change from `False` to `True` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `True` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n",
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\imblearn\\ensemble\\_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random Forest - Training Accuracy: 0.7809143909174593\n",
      "Random Forest - Test Accuracy: 0.6404907975460122\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.65      0.66       861\n",
      "           1       0.62      0.63      0.62       769\n",
      "\n",
      "    accuracy                           0.64      1630\n",
      "   macro avg       0.64      0.64      0.64      1630\n",
      "weighted avg       0.64      0.64      0.64      1630\n",
      "\n",
      "Confusion Matrix:\n",
      "[[562 299]\n",
      " [287 482]]\n",
      "ROC AUC Score: 0.6397587104238124\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=['FTRT', 'FTR'], axis = 1)  # Features\n",
    "y = df['FTRT']  # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "\n",
    "# Random Forest\n",
    "rf_model = BalancedRandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, min_samples_leaf=10, random_state=42)\n",
    "\n",
    "# Train models\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "rf_train_preds = rf_model.predict(X_train)\n",
    "rf_test_preds = rf_model.predict(X_test)\n",
    "\n",
    "# Accuracy scores\n",
    "rf_train_accuracy = accuracy_score(y_train, rf_train_preds)\n",
    "rf_test_accuracy = accuracy_score(y_test, rf_test_preds)\n",
    "\n",
    "print(\"\\nRandom Forest - Training Accuracy:\", rf_train_accuracy)\n",
    "print(\"Random Forest - Test Accuracy:\", rf_test_accuracy)\n",
    "\n",
    "rf_feature_importances = rf_model.feature_importances_\n",
    "\n",
    "# Visualize accuracy scores\n",
    "models = ['Random Forest']\n",
    "train_accuracies = [rf_train_accuracy]\n",
    "test_accuracies = [rf_test_accuracy]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(models, train_accuracies, color='skyblue', label='Training Accuracy')\n",
    "plt.bar(models, test_accuracies, color='orange', alpha=0.7, label='Test Accuracy')\n",
    "plt.title('Accuracy Scores of Different Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0.5, 1)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Visualize feature importances\n",
    "rf_feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': rf_feature_importances})\n",
    "\n",
    "sns.barplot(x='Importance', y='Feature', data=rf_feature_importances_df.sort_values(by='Importance', ascending=False))\n",
    "plt.title('Random Forest Feature Importances')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_test, rf_test_preds))\n",
    "\n",
    "# Calculate and print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, rf_test_preds)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Calculate ROC AUC score\n",
    "roc_auc = roc_auc_score(y_test, rf_test_preds)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.feature_selection import SelectKBest, f_classif\\nfrom sklearn.model_selection import cross_val_score\\n\\n# Perform feature selection\\nmodel = BalancedRandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, min_samples_leaf=10, random_state=42,\\n                                        sampling_strategy = \\'all\\', replacement = True, bootstrap = False)\\n\\nfor k in range(1, len(X_train.columns)):\\n    selector = SelectKBest(score_func=f_classif, k=k)  # Example: Select top 5 features\\n    X_selected = selector.fit_transform(X, y)\\n    # Evaluate model with cross-validation\\n    cv_scores = cross_val_score(model, X_selected, y, cv=5, scoring=\\'roc_auc\\')\\n\\n    # Calculate average ROC AUC score\\n    avg_roc_auc = cv_scores.mean()\\n    print(\"Average ROC AUC score:\", avg_roc_auc, \\'and number of features: \\', k)\\n\\nX_selected = selector.fit_transform(X, y)\\n\\n# Get indices of selected features\\nselected_indices = selector.get_support(indices=True)\\n\\n# Get names of selected features\\nselected_feature_names = X_train.columns[selected_indices]\\n\\nprint(\"Selected features:\", selected_feature_names)\\n\\n# Evaluate model with cross-validation\\ncv_scores = cross_val_score(model, X_selected, y, cv=5, scoring=\\'roc_auc\\')\\n\\n# Calculate average ROC AUC score\\navg_roc_auc = cv_scores.mean()\\n\\nprint(\"Average ROC AUC score:\", avg_roc_auc)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform feature selection\n",
    "model = BalancedRandomForestClassifier(n_estimators=200, max_depth=20, min_samples_split=10, min_samples_leaf=10, random_state=42,\n",
    "                                        sampling_strategy = 'all', replacement = True, bootstrap = False)\n",
    "\n",
    "for k in range(1, len(X_train.columns)):\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)  # Example: Select top 5 features\n",
    "    X_selected = selector.fit_transform(X, y)\n",
    "    # Evaluate model with cross-validation\n",
    "    cv_scores = cross_val_score(model, X_selected, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "    # Calculate average ROC AUC score\n",
    "    avg_roc_auc = cv_scores.mean()\n",
    "    print(\"Average ROC AUC score:\", avg_roc_auc, 'and number of features: ', k)\n",
    "\n",
    "X_selected = selector.fit_transform(X, y)\n",
    "\n",
    "# Get indices of selected features\n",
    "selected_indices = selector.get_support(indices=True)\n",
    "\n",
    "# Get names of selected features\n",
    "selected_feature_names = X_train.columns[selected_indices]\n",
    "\n",
    "print(\"Selected features:\", selected_feature_names)\n",
    "\n",
    "# Evaluate model with cross-validation\n",
    "cv_scores = cross_val_score(model, X_selected, y, cv=5, scoring='roc_auc')\n",
    "\n",
    "# Calculate average ROC AUC score\n",
    "avg_roc_auc = cv_scores.mean()\n",
    "\n",
    "print(\"Average ROC AUC score:\", avg_roc_auc)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shallow Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.6320 - loss: 0.6576 - val_accuracy: 0.6250 - val_loss: 0.6322\n",
      "Epoch 2/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6499 - loss: 0.6291 - val_accuracy: 0.6518 - val_loss: 0.6244\n",
      "Epoch 3/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6568 - loss: 0.6316 - val_accuracy: 0.6518 - val_loss: 0.6377\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6554 - loss: 0.6306 - val_accuracy: 0.6564 - val_loss: 0.6210\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6479 - loss: 0.6299 - val_accuracy: 0.6296 - val_loss: 0.6391\n",
      "Epoch 6/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6440 - loss: 0.6293 - val_accuracy: 0.6472 - val_loss: 0.6445\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6586 - loss: 0.6200 - val_accuracy: 0.6587 - val_loss: 0.6173\n",
      "Epoch 8/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6564 - loss: 0.6193 - val_accuracy: 0.6488 - val_loss: 0.6608\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6494 - loss: 0.6369 - val_accuracy: 0.6549 - val_loss: 0.6235\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6656 - loss: 0.6224 - val_accuracy: 0.6702 - val_loss: 0.6311\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6668 - loss: 0.6239 - val_accuracy: 0.6350 - val_loss: 0.6314\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 0.6185 - val_accuracy: 0.6549 - val_loss: 0.6212\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6593 - loss: 0.6227 - val_accuracy: 0.6564 - val_loss: 0.6193\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6582 - loss: 0.6128 - val_accuracy: 0.6549 - val_loss: 0.6202\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6692 - loss: 0.6087 - val_accuracy: 0.6595 - val_loss: 0.6260\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6592 - loss: 0.6236 - val_accuracy: 0.6610 - val_loss: 0.6266\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6650 - loss: 0.6196 - val_accuracy: 0.6495 - val_loss: 0.6197\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6588 - loss: 0.6224 - val_accuracy: 0.6465 - val_loss: 0.6192\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6642 - loss: 0.6089 - val_accuracy: 0.6564 - val_loss: 0.6195\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6666 - loss: 0.6181 - val_accuracy: 0.6541 - val_loss: 0.6184\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6531 - loss: 0.6219 - val_accuracy: 0.6618 - val_loss: 0.6258\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6567 - loss: 0.6268 - val_accuracy: 0.6595 - val_loss: 0.6153\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6763 - loss: 0.6084 - val_accuracy: 0.6097 - val_loss: 0.6442\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6665 - loss: 0.6103 - val_accuracy: 0.6265 - val_loss: 0.6364\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6663 - loss: 0.6163 - val_accuracy: 0.6518 - val_loss: 0.6231\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6727 - loss: 0.6040 - val_accuracy: 0.6687 - val_loss: 0.6196\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.6141 - val_accuracy: 0.6242 - val_loss: 0.6412\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6617 - loss: 0.6126 - val_accuracy: 0.6480 - val_loss: 0.6307\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6656 - loss: 0.6151 - val_accuracy: 0.6603 - val_loss: 0.6230\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6650 - loss: 0.6198 - val_accuracy: 0.6564 - val_loss: 0.6160\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6594 - loss: 0.6135 - val_accuracy: 0.6426 - val_loss: 0.6382\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6603 - loss: 0.6221 - val_accuracy: 0.6526 - val_loss: 0.6418\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6533 - loss: 0.6158 - val_accuracy: 0.6334 - val_loss: 0.6432\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6593 - loss: 0.6140 - val_accuracy: 0.6258 - val_loss: 0.6493\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6651 - loss: 0.6130 - val_accuracy: 0.6580 - val_loss: 0.6160\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6762 - loss: 0.6056 - val_accuracy: 0.6480 - val_loss: 0.6240\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6700 - loss: 0.6071 - val_accuracy: 0.6656 - val_loss: 0.6146\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6613 - loss: 0.6124 - val_accuracy: 0.6649 - val_loss: 0.6277\n",
      "Epoch 39/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6758 - loss: 0.6081 - val_accuracy: 0.6403 - val_loss: 0.6315\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6639 - loss: 0.6134 - val_accuracy: 0.6449 - val_loss: 0.6182\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6709 - loss: 0.6089 - val_accuracy: 0.6672 - val_loss: 0.6129\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6725 - loss: 0.6074 - val_accuracy: 0.6534 - val_loss: 0.6167\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6790 - loss: 0.5977 - val_accuracy: 0.6526 - val_loss: 0.6171\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6730 - loss: 0.6100 - val_accuracy: 0.6603 - val_loss: 0.6146\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6672 - loss: 0.6068 - val_accuracy: 0.6541 - val_loss: 0.6168\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6720 - loss: 0.5983 - val_accuracy: 0.6618 - val_loss: 0.6211\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6662 - loss: 0.6098 - val_accuracy: 0.6549 - val_loss: 0.6187\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6696 - loss: 0.6030 - val_accuracy: 0.6610 - val_loss: 0.6267\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6624 - loss: 0.6073 - val_accuracy: 0.6587 - val_loss: 0.6202\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6698 - loss: 0.6019 - val_accuracy: 0.6595 - val_loss: 0.6154\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6766 - loss: 0.6049 - val_accuracy: 0.6342 - val_loss: 0.6251\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6539 - loss: 0.6152 - val_accuracy: 0.6503 - val_loss: 0.6275\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6582 - loss: 0.6210 - val_accuracy: 0.6580 - val_loss: 0.6196\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6595 - loss: 0.6149 - val_accuracy: 0.6641 - val_loss: 0.6225\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 0.6043 - val_accuracy: 0.6557 - val_loss: 0.6229\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6707 - loss: 0.6024 - val_accuracy: 0.6319 - val_loss: 0.6379\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6699 - loss: 0.6083 - val_accuracy: 0.6641 - val_loss: 0.6226\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6748 - loss: 0.5944 - val_accuracy: 0.6334 - val_loss: 0.6286\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6599 - loss: 0.6120 - val_accuracy: 0.6396 - val_loss: 0.6400\n",
      "Epoch 60/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.6131 - val_accuracy: 0.6281 - val_loss: 0.6410\n",
      "Epoch 61/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.6138 - val_accuracy: 0.6587 - val_loss: 0.6163\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6690 - loss: 0.6057 - val_accuracy: 0.6457 - val_loss: 0.6257\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6741 - loss: 0.6069 - val_accuracy: 0.6626 - val_loss: 0.6182\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6762 - loss: 0.5968 - val_accuracy: 0.6641 - val_loss: 0.6141\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6649 - loss: 0.6068 - val_accuracy: 0.6411 - val_loss: 0.6243\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6690 - loss: 0.6007 - val_accuracy: 0.6442 - val_loss: 0.6253\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6878 - loss: 0.5952 - val_accuracy: 0.6342 - val_loss: 0.6357\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.6082 - val_accuracy: 0.6595 - val_loss: 0.6234\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6752 - loss: 0.5997 - val_accuracy: 0.6503 - val_loss: 0.6179\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6700 - loss: 0.6017 - val_accuracy: 0.6480 - val_loss: 0.6249\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6667 - loss: 0.5998 - val_accuracy: 0.6572 - val_loss: 0.6188\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6844 - loss: 0.5948 - val_accuracy: 0.6534 - val_loss: 0.6255\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6626 - loss: 0.6109 - val_accuracy: 0.6595 - val_loss: 0.6157\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6788 - loss: 0.5913 - val_accuracy: 0.6564 - val_loss: 0.6130\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6772 - loss: 0.5981 - val_accuracy: 0.6649 - val_loss: 0.6183\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6765 - loss: 0.5960 - val_accuracy: 0.6426 - val_loss: 0.6269\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6750 - loss: 0.6025 - val_accuracy: 0.6603 - val_loss: 0.6230\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6717 - loss: 0.6095 - val_accuracy: 0.6557 - val_loss: 0.6228\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 0.5874 - val_accuracy: 0.6610 - val_loss: 0.6178\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6676 - loss: 0.6044 - val_accuracy: 0.6227 - val_loss: 0.6453\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6782 - loss: 0.6016 - val_accuracy: 0.6511 - val_loss: 0.6181\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6751 - loss: 0.5978 - val_accuracy: 0.6641 - val_loss: 0.6195\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 0.6092 - val_accuracy: 0.6503 - val_loss: 0.6383\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.5902 - val_accuracy: 0.6526 - val_loss: 0.6360\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6743 - loss: 0.5988 - val_accuracy: 0.6380 - val_loss: 0.6340\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6720 - loss: 0.5964 - val_accuracy: 0.6664 - val_loss: 0.6138\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.6011 - val_accuracy: 0.6587 - val_loss: 0.6193\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6785 - loss: 0.5889 - val_accuracy: 0.6380 - val_loss: 0.6258\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6731 - loss: 0.6019 - val_accuracy: 0.6572 - val_loss: 0.6209\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6799 - loss: 0.5935 - val_accuracy: 0.6649 - val_loss: 0.6157\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6729 - loss: 0.5962 - val_accuracy: 0.6534 - val_loss: 0.6324\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6861 - loss: 0.5954 - val_accuracy: 0.6511 - val_loss: 0.6180\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6742 - loss: 0.5974 - val_accuracy: 0.6672 - val_loss: 0.6207\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6826 - loss: 0.5911 - val_accuracy: 0.6534 - val_loss: 0.6187\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6879 - loss: 0.5896 - val_accuracy: 0.6587 - val_loss: 0.6199\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.6007 - val_accuracy: 0.6656 - val_loss: 0.6161\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6771 - loss: 0.5918 - val_accuracy: 0.6603 - val_loss: 0.6179\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6878 - loss: 0.5880 - val_accuracy: 0.6649 - val_loss: 0.6293\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.5937 - val_accuracy: 0.6449 - val_loss: 0.6378\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6756 - loss: 0.5912 - val_accuracy: 0.6664 - val_loss: 0.6175\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6350 - loss: 0.6568\n",
      "Test Accuracy: 0.6472392678260803\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Sequential\n",
    "\n",
    "# Assuming X_train and y_train are your training data and labels\n",
    "# Assuming X_test and y_test are your testing data and labels\n",
    "\n",
    "# Define the architecture of the shallow neural network\n",
    "model = Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking with LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.6283 - loss: 0.6535\n",
      "Epoch 2/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6584 - loss: 0.6295\n",
      "Epoch 3/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6575 - loss: 0.6280\n",
      "Epoch 4/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6474 - loss: 0.6319\n",
      "Epoch 5/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6487 - loss: 0.6250\n",
      "Epoch 6/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6463 - loss: 0.6288\n",
      "Epoch 7/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6504 - loss: 0.6254\n",
      "Epoch 8/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6568 - loss: 0.6253\n",
      "Epoch 9/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6486 - loss: 0.6261\n",
      "Epoch 10/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6572 - loss: 0.6218\n",
      "Epoch 11/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6510 - loss: 0.6317\n",
      "Epoch 12/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6441 - loss: 0.6277\n",
      "Epoch 13/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6527 - loss: 0.6220\n",
      "Epoch 14/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6457 - loss: 0.6300\n",
      "Epoch 15/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6658 - loss: 0.6145\n",
      "Epoch 16/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6567 - loss: 0.6245\n",
      "Epoch 17/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6515 - loss: 0.6238\n",
      "Epoch 18/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6475 - loss: 0.6240\n",
      "Epoch 19/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6494 - loss: 0.6217\n",
      "Epoch 20/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6562 - loss: 0.6189\n",
      "Epoch 21/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6540 - loss: 0.6244\n",
      "Epoch 22/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6570 - loss: 0.6229\n",
      "Epoch 23/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6617 - loss: 0.6164\n",
      "Epoch 24/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6503 - loss: 0.6256\n",
      "Epoch 25/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6638 - loss: 0.6185\n",
      "Epoch 26/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6628 - loss: 0.6216\n",
      "Epoch 27/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6565 - loss: 0.6215\n",
      "Epoch 28/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6560 - loss: 0.6216\n",
      "Epoch 29/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6586 - loss: 0.6185\n",
      "Epoch 30/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6502 - loss: 0.6254\n",
      "Epoch 31/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6583 - loss: 0.6208\n",
      "Epoch 32/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6445 - loss: 0.6291\n",
      "Epoch 33/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6654 - loss: 0.6193\n",
      "Epoch 34/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6648 - loss: 0.6207\n",
      "Epoch 35/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6558 - loss: 0.6181\n",
      "Epoch 36/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6660 - loss: 0.6152\n",
      "Epoch 37/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6490 - loss: 0.6258\n",
      "Epoch 38/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6647 - loss: 0.6143\n",
      "Epoch 39/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6565 - loss: 0.6192\n",
      "Epoch 40/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6565 - loss: 0.6199\n",
      "Epoch 41/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6554 - loss: 0.6193\n",
      "Epoch 42/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6629 - loss: 0.6132\n",
      "Epoch 43/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6600 - loss: 0.6197\n",
      "Epoch 44/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6625 - loss: 0.6120\n",
      "Epoch 45/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6576 - loss: 0.6152\n",
      "Epoch 46/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6550 - loss: 0.6192\n",
      "Epoch 47/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6559 - loss: 0.6189\n",
      "Epoch 48/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6502 - loss: 0.6219\n",
      "Epoch 49/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6561 - loss: 0.6217\n",
      "Epoch 50/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6619 - loss: 0.6196\n",
      "Epoch 51/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6476 - loss: 0.6257\n",
      "Epoch 52/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6621 - loss: 0.6201\n",
      "Epoch 53/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6600 - loss: 0.6200\n",
      "Epoch 54/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6605 - loss: 0.6172\n",
      "Epoch 55/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6613 - loss: 0.6172\n",
      "Epoch 56/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6598 - loss: 0.6153\n",
      "Epoch 57/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6615 - loss: 0.6142\n",
      "Epoch 58/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6547 - loss: 0.6179\n",
      "Epoch 59/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6498 - loss: 0.6255\n",
      "Epoch 60/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6670 - loss: 0.6101\n",
      "Epoch 61/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6603 - loss: 0.6169\n",
      "Epoch 62/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6609 - loss: 0.6174\n",
      "Epoch 63/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6656 - loss: 0.6176\n",
      "Epoch 64/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6635 - loss: 0.6127\n",
      "Epoch 65/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6675 - loss: 0.6126\n",
      "Epoch 66/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6624 - loss: 0.6166\n",
      "Epoch 67/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6588 - loss: 0.6113\n",
      "Epoch 68/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6659 - loss: 0.6100\n",
      "Epoch 69/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6539 - loss: 0.6192\n",
      "Epoch 70/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6620 - loss: 0.6088\n",
      "Epoch 71/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6586 - loss: 0.6139\n",
      "Epoch 72/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6666 - loss: 0.6110\n",
      "Epoch 73/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6574 - loss: 0.6143\n",
      "Epoch 74/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6581 - loss: 0.6115\n",
      "Epoch 75/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6676 - loss: 0.6118\n",
      "Epoch 76/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6643 - loss: 0.6117\n",
      "Epoch 77/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6720 - loss: 0.6095\n",
      "Epoch 78/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6661 - loss: 0.6061\n",
      "Epoch 79/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6612 - loss: 0.6120\n",
      "Epoch 80/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6689 - loss: 0.6072\n",
      "Epoch 81/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6701 - loss: 0.6020\n",
      "Epoch 82/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6714 - loss: 0.6021\n",
      "Epoch 83/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6673 - loss: 0.6076\n",
      "Epoch 84/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6700 - loss: 0.6051\n",
      "Epoch 85/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6753 - loss: 0.6032\n",
      "Epoch 86/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6663 - loss: 0.6108\n",
      "Epoch 87/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6586 - loss: 0.6146\n",
      "Epoch 88/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6780 - loss: 0.6038\n",
      "Epoch 89/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6612 - loss: 0.6050\n",
      "Epoch 90/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6660 - loss: 0.6042\n",
      "Epoch 91/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6660 - loss: 0.6049\n",
      "Epoch 92/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6681 - loss: 0.6119\n",
      "Epoch 93/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6737 - loss: 0.5980\n",
      "Epoch 94/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6736 - loss: 0.5972\n",
      "Epoch 95/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6719 - loss: 0.6054\n",
      "Epoch 96/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6706 - loss: 0.6068\n",
      "Epoch 97/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6584 - loss: 0.6135\n",
      "Epoch 98/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6676 - loss: 0.6089\n",
      "Epoch 99/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6718 - loss: 0.6002\n",
      "Epoch 100/100\n",
      "\u001b[1m102/102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6731 - loss: 0.6000\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6204 - loss: 0.6589\n",
      "Test Accuracy: 0.6202453970909119\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Define LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(units=64, input_shape=(X_train.shape[1], 1), return_sequences = True),  # LSTM layer with 50 units\n",
    "    LSTM(units=32),\n",
    "    Dense(units=1, activation='sigmoid')  # Output layer (binary classification)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\99451\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.6611 - loss: 0.6336 - val_accuracy: 0.6488 - val_loss: 0.6229\n",
      "Epoch 2/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6539 - loss: 0.6261 - val_accuracy: 0.6350 - val_loss: 0.6396\n",
      "Epoch 3/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6556 - loss: 0.6198 - val_accuracy: 0.6442 - val_loss: 0.6316\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6439 - loss: 0.6351 - val_accuracy: 0.6534 - val_loss: 0.6364\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6684 - loss: 0.6184 - val_accuracy: 0.6304 - val_loss: 0.6404\n",
      "Epoch 6/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6650 - loss: 0.6207 - val_accuracy: 0.6580 - val_loss: 0.6180\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6723 - loss: 0.6117 - val_accuracy: 0.6495 - val_loss: 0.6227\n",
      "Epoch 8/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6658 - loss: 0.6132 - val_accuracy: 0.6480 - val_loss: 0.6225\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6626 - loss: 0.6151 - val_accuracy: 0.6587 - val_loss: 0.6167\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6525 - loss: 0.6209 - val_accuracy: 0.6572 - val_loss: 0.6253\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6707 - loss: 0.6093 - val_accuracy: 0.6564 - val_loss: 0.6138\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6602 - loss: 0.6131 - val_accuracy: 0.6633 - val_loss: 0.6160\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6704 - loss: 0.6052 - val_accuracy: 0.6480 - val_loss: 0.6238\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6712 - loss: 0.6084 - val_accuracy: 0.6549 - val_loss: 0.6169\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6717 - loss: 0.6084 - val_accuracy: 0.6411 - val_loss: 0.6277\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6596 - loss: 0.6123 - val_accuracy: 0.6626 - val_loss: 0.6147\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6685 - loss: 0.6090 - val_accuracy: 0.6564 - val_loss: 0.6277\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6818 - loss: 0.5982 - val_accuracy: 0.6488 - val_loss: 0.6190\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6750 - loss: 0.6011 - val_accuracy: 0.6626 - val_loss: 0.6169\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6821 - loss: 0.6004 - val_accuracy: 0.6518 - val_loss: 0.6137\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6740 - loss: 0.6028 - val_accuracy: 0.6495 - val_loss: 0.6203\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6721 - loss: 0.6032 - val_accuracy: 0.6572 - val_loss: 0.6214\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6695 - loss: 0.6011 - val_accuracy: 0.6633 - val_loss: 0.6209\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6751 - loss: 0.6052 - val_accuracy: 0.6495 - val_loss: 0.6283\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6726 - loss: 0.6086 - val_accuracy: 0.6610 - val_loss: 0.6186\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6750 - loss: 0.6029 - val_accuracy: 0.6465 - val_loss: 0.6192\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6675 - loss: 0.6003 - val_accuracy: 0.6534 - val_loss: 0.6211\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6736 - loss: 0.6039 - val_accuracy: 0.6641 - val_loss: 0.6201\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6677 - loss: 0.5991 - val_accuracy: 0.6526 - val_loss: 0.6205\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6888 - loss: 0.5952 - val_accuracy: 0.6526 - val_loss: 0.6280\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6840 - loss: 0.5960 - val_accuracy: 0.6572 - val_loss: 0.6219\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6829 - loss: 0.5924 - val_accuracy: 0.6549 - val_loss: 0.6231\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6848 - loss: 0.5933 - val_accuracy: 0.6426 - val_loss: 0.6191\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6892 - loss: 0.5884 - val_accuracy: 0.6595 - val_loss: 0.6187\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6854 - loss: 0.5933 - val_accuracy: 0.6656 - val_loss: 0.6236\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6806 - loss: 0.5956 - val_accuracy: 0.6534 - val_loss: 0.6199\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6893 - loss: 0.5821 - val_accuracy: 0.6618 - val_loss: 0.6289\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6859 - loss: 0.5882 - val_accuracy: 0.6503 - val_loss: 0.6249\n",
      "Epoch 39/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6969 - loss: 0.5770 - val_accuracy: 0.6426 - val_loss: 0.6240\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6981 - loss: 0.5820 - val_accuracy: 0.6695 - val_loss: 0.6256\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6932 - loss: 0.5796 - val_accuracy: 0.6595 - val_loss: 0.6273\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7059 - loss: 0.5776 - val_accuracy: 0.6396 - val_loss: 0.6283\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6916 - loss: 0.5878 - val_accuracy: 0.6465 - val_loss: 0.6299\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7008 - loss: 0.5732 - val_accuracy: 0.6511 - val_loss: 0.6221\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7010 - loss: 0.5776 - val_accuracy: 0.6434 - val_loss: 0.6313\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6922 - loss: 0.5835 - val_accuracy: 0.6534 - val_loss: 0.6258\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7128 - loss: 0.5636 - val_accuracy: 0.6457 - val_loss: 0.6244\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7069 - loss: 0.5700 - val_accuracy: 0.6526 - val_loss: 0.6219\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6996 - loss: 0.5721 - val_accuracy: 0.6449 - val_loss: 0.6306\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7156 - loss: 0.5629 - val_accuracy: 0.6534 - val_loss: 0.6286\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7054 - loss: 0.5668 - val_accuracy: 0.6396 - val_loss: 0.6308\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7084 - loss: 0.5648 - val_accuracy: 0.6457 - val_loss: 0.6238\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7099 - loss: 0.5592 - val_accuracy: 0.6235 - val_loss: 0.6422\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7155 - loss: 0.5608 - val_accuracy: 0.6480 - val_loss: 0.6273\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7197 - loss: 0.5471 - val_accuracy: 0.6319 - val_loss: 0.6288\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7071 - loss: 0.5587 - val_accuracy: 0.6595 - val_loss: 0.6224\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7096 - loss: 0.5624 - val_accuracy: 0.6442 - val_loss: 0.6304\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7152 - loss: 0.5547 - val_accuracy: 0.6557 - val_loss: 0.6298\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 0.5614 - val_accuracy: 0.6511 - val_loss: 0.6372\n",
      "Epoch 60/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7173 - loss: 0.5494 - val_accuracy: 0.6495 - val_loss: 0.6414\n",
      "Epoch 61/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7077 - loss: 0.5614 - val_accuracy: 0.6549 - val_loss: 0.6268\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7174 - loss: 0.5421 - val_accuracy: 0.6587 - val_loss: 0.6397\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7224 - loss: 0.5452 - val_accuracy: 0.6465 - val_loss: 0.6404\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7275 - loss: 0.5448 - val_accuracy: 0.6549 - val_loss: 0.6431\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7160 - loss: 0.5406 - val_accuracy: 0.6465 - val_loss: 0.6375\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7351 - loss: 0.5418 - val_accuracy: 0.6511 - val_loss: 0.6413\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7257 - loss: 0.5393 - val_accuracy: 0.6618 - val_loss: 0.6357\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7213 - loss: 0.5454 - val_accuracy: 0.6580 - val_loss: 0.6534\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.5420 - val_accuracy: 0.6250 - val_loss: 0.6648\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7281 - loss: 0.5280 - val_accuracy: 0.6480 - val_loss: 0.6492\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7444 - loss: 0.5251 - val_accuracy: 0.6526 - val_loss: 0.6571\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7375 - loss: 0.5271 - val_accuracy: 0.6327 - val_loss: 0.6464\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7298 - loss: 0.5284 - val_accuracy: 0.6449 - val_loss: 0.6584\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7371 - loss: 0.5230 - val_accuracy: 0.6488 - val_loss: 0.6618\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7458 - loss: 0.5132 - val_accuracy: 0.6380 - val_loss: 0.6577\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7423 - loss: 0.5153 - val_accuracy: 0.6511 - val_loss: 0.6627\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7524 - loss: 0.5015 - val_accuracy: 0.6388 - val_loss: 0.6548\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7428 - loss: 0.5168 - val_accuracy: 0.6403 - val_loss: 0.6674\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7338 - loss: 0.5189 - val_accuracy: 0.6396 - val_loss: 0.6735\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7519 - loss: 0.5120 - val_accuracy: 0.6396 - val_loss: 0.6692\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7417 - loss: 0.5018 - val_accuracy: 0.6403 - val_loss: 0.6643\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7493 - loss: 0.5113 - val_accuracy: 0.6495 - val_loss: 0.6823\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7453 - loss: 0.5071 - val_accuracy: 0.6388 - val_loss: 0.6684\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7647 - loss: 0.4931 - val_accuracy: 0.6258 - val_loss: 0.6783\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7722 - loss: 0.4751 - val_accuracy: 0.6281 - val_loss: 0.6907\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7583 - loss: 0.4943 - val_accuracy: 0.6426 - val_loss: 0.6842\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7610 - loss: 0.4834 - val_accuracy: 0.6304 - val_loss: 0.6953\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7727 - loss: 0.4807 - val_accuracy: 0.6227 - val_loss: 0.7073\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7726 - loss: 0.4751 - val_accuracy: 0.6334 - val_loss: 0.6924\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7830 - loss: 0.4693 - val_accuracy: 0.6388 - val_loss: 0.7077\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7696 - loss: 0.4710 - val_accuracy: 0.6357 - val_loss: 0.7001\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7633 - loss: 0.4737 - val_accuracy: 0.6181 - val_loss: 0.7048\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7864 - loss: 0.4624 - val_accuracy: 0.6350 - val_loss: 0.7005\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7818 - loss: 0.4527 - val_accuracy: 0.6258 - val_loss: 0.7080\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7772 - loss: 0.4648 - val_accuracy: 0.6219 - val_loss: 0.7117\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7702 - loss: 0.4638 - val_accuracy: 0.6189 - val_loss: 0.7253\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7886 - loss: 0.4440 - val_accuracy: 0.6104 - val_loss: 0.7100\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.4616 - val_accuracy: 0.6311 - val_loss: 0.7242\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7902 - loss: 0.4502 - val_accuracy: 0.6380 - val_loss: 0.7078\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8021 - loss: 0.4400 - val_accuracy: 0.6258 - val_loss: 0.7479\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5916 - loss: 0.7850\n",
      "Test Accuracy: 0.5914110541343689\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.SimpleRNN(64, input_shape = (X_train.shape[1], 1), return_sequences = True),  # 10 time steps, 1 input dimension\n",
    "    tf.keras.layers.SimpleRNN(32),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with sigmoid activation\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
